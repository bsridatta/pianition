{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from os.path import isfile\n",
    "from datetime import datetime\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.utils import plot_model\n",
    "from keras.layers import Input, Dense, TimeDistributed, LSTM, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, MaxPooling2D, Reshape\n",
    "from keras.layers import Conv2D, BatchNormalization, Lambda, Permute, GRU\n",
    "from keras.layers.advanced_activations import ELU\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from keras import backend\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras import regularizers\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "#sys.path.insert(0, '/home/nik/kth/y1p1/speech/project/')\n",
    "from pianition.data_util import load_dataset\n",
    "\n",
    "run_in_debug=False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHUFFLE_BUFFER = 100\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 12\n",
    "\n",
    "# Create a description of the features.  \n",
    "feature_description = {\n",
    "    'feature0': tf.FixedLenFeature([32768], tf.float32),\n",
    "    'feature1': tf.FixedLenFeature([1], tf.int64)\n",
    "}\n",
    "\n",
    "def _parse_function(example_proto):\n",
    "  # Parse the input tf.Example proto using the dictionary above.\n",
    "    parsed_example = tf.parse_single_example(example_proto, feature_description)\n",
    "    parsed_example[\"feature0\"] = tf.transpose(tf.reshape(parsed_example['feature0'], (256,128)))\n",
    "    return parsed_example\n",
    "\n",
    "def create_dataset(filepath):\n",
    "    \n",
    "    dataset = tf.data.TFRecordDataset(filepath)\n",
    "    \n",
    "    dataset = dataset.map(_parse_function) #, num_parallel_calls=8)\n",
    "    \n",
    "    # This dataset will go on forever\n",
    "    dataset = dataset.repeat()\n",
    "    \n",
    "    # Set the number of datapoints you want to load and shuffle \n",
    "    dataset = dataset.shuffle(SHUFFLE_BUFFER)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    \n",
    "    # Create an iterator\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    \n",
    "    # Create your tf representation of the iterator\n",
    "    feature = iterator.get_next()\n",
    "    #print(feature)\n",
    "    lmfcc = feature[\"feature0\"]\n",
    "    label = feature[\"feature1\"]\n",
    "    \n",
    "    # Bring your picture back in shape\n",
    "    lmfcc = tf.reshape(lmfcc, [-1,128, 256])\n",
    "    \n",
    "    # Create a one hot array for your labels\n",
    "    label = tf.one_hot(label, NUM_CLASSES)\n",
    "    print(\"inp\",lmfcc.shape)\n",
    "    print(\"inp\",label.shape)\n",
    "\n",
    "    return lmfcc, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inp (?, 128, 256)\n",
      "inp (?, 1, 12)\n"
     ]
    }
   ],
   "source": [
    "lmfcc, label = create_dataset(\"../data/full/sample.tfrecords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callbacks(checkpoint_name):\n",
    "    logDir = \"./Graph/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "    tb = TensorBoard(log_dir=logDir,\n",
    "                     histogram_freq=2,\n",
    "                     write_graph=True,\n",
    "                     write_images=True,\n",
    "                     write_grads=True,\n",
    "                     update_freq='epoch')\n",
    "\n",
    "#     tb_callback = TensorBoard(\n",
    "#         log_dir='../models/logs/',\n",
    "#         histogram_freq=1,\n",
    "#         batch_size=32,\n",
    "#         write_graph=True,\n",
    "#         write_grads=False,\n",
    "#         write_images=False,\n",
    "#         embeddings_freq=0,\n",
    "#         embeddings_layer_names=None,\n",
    "#         embeddings_metadata=None,\n",
    "#     )\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint('../models/' + checkpoint_name +\n",
    "                                          '{epoch:02d}-{val_loss:.2f}.hdf5',\n",
    "                                          monitor='val_acc',\n",
    "                                          verbose=1,\n",
    "                                          save_best_only=True,\n",
    "                                          mode='max')\n",
    "\n",
    "    reducelr_callback = ReduceLROnPlateau(monitor='val_acc',\n",
    "                                          factor=0.5,\n",
    "                                          patience=10,\n",
    "                                          min_delta=0.01,\n",
    "                                          verbose=1)\n",
    "\n",
    "    callback_list = [checkpoint_callback, reducelr_callback]\n",
    "\n",
    "    return callback_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inp (?, 128, 256)\n",
      "inp (?, 1, 12)\n",
      "inp (?, 128, 256)\n",
      "inp (?, 1, 12)\n"
     ]
    }
   ],
   "source": [
    "debug_num_train_samples = 494\n",
    "debug_num_val_samples = 150\n",
    "\n",
    "full_num_train_samples = 21504\n",
    "full_num_val_samples = 6969\n",
    "\n",
    "if run_in_debug:\n",
    "    lmfcc, label = create_dataset(\"../data/debug/train.tfrecords\")\n",
    "    lmfcc_val, label_val = create_dataset(\"../data/debug/val.tfrecords\")\n",
    "    num_train = debug_num_train_samples\n",
    "    num_val = debug_num_val_samples\n",
    "else:\n",
    "    lmfcc, label = create_dataset(\"../data/debug/train.tfrecords\")\n",
    "    lmfcc_val, label_val = create_dataset(\"../data/debug/val.tfrecords\")\n",
    "    num_train = full_num_train_samples\n",
    "    num_val = full_num_val_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 128, 256)\n",
      "(?, 256, 128)\n",
      "Epoch 1/70\n",
      "672/672 [==============================] - 91s 135ms/step - loss: 2.4600 - acc: 0.1020 - val_loss: 2.2780 - val_acc: 0.1678\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.16777, saving model to ../models/trail01-2.28.hdf5\n",
      "Epoch 2/70\n",
      "672/672 [==============================] - 91s 136ms/step - loss: 2.3319 - acc: 0.1360 - val_loss: 2.2699 - val_acc: 0.1804\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.16777 to 0.18044, saving model to ../models/trail02-2.27.hdf5\n",
      "Epoch 3/70\n",
      "672/672 [==============================] - 88s 132ms/step - loss: 2.3097 - acc: 0.1564 - val_loss: 2.2700 - val_acc: 0.1802\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.18044\n",
      "Epoch 4/70\n",
      "672/672 [==============================] - 85s 127ms/step - loss: 2.2966 - acc: 0.1668 - val_loss: 2.2677 - val_acc: 0.1804\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.18044\n",
      "Epoch 5/70\n",
      "672/672 [==============================] - 90s 134ms/step - loss: 2.2913 - acc: 0.1716 - val_loss: 2.2645 - val_acc: 0.1802\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.18044\n",
      "Epoch 6/70\n",
      "672/672 [==============================] - 100s 149ms/step - loss: 2.2872 - acc: 0.1759 - val_loss: 2.2663 - val_acc: 0.1820\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.18044 to 0.18203, saving model to ../models/trail06-2.27.hdf5\n",
      "Epoch 7/70\n",
      " 91/672 [===>..........................] - ETA: 1:01 - loss: 2.3003 - acc: 0.1816"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-59c6627ca181>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlmfcc_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_val\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 callbacks=get_callbacks(checkpoint_name=\"trail\"))\n\u001b[0m",
      "\u001b[0;32m~/kth/y1p1/speech/project/venv/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/kth/y1p1/speech/project/venv/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kth/y1p1/speech/project/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kth/y1p1/speech/project/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kth/y1p1/speech/project/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Build network\n",
    "NUM_CLASSES = 12  # Must Change in the tf reader as well\n",
    "N_LAYERS = 3\n",
    "CONV_FILTER_COUNT = 64\n",
    "FILTER_LENGTH = 5\n",
    "\n",
    "POOL_SIZE = 2\n",
    "\n",
    "GRU_COUNT = 64\n",
    "NUM_HIDDEN = 128\n",
    "L2_regularization = 0.001\n",
    "\n",
    "BATCH_SIZE=32\n",
    "\n",
    "# Input\n",
    "model_input = keras.layers.Input(tensor=lmfcc)\n",
    "print(model_input.shape)\n",
    "layer = Permute((2, 1), input_shape=(128, 256))(model_input)\n",
    "print(layer.shape)\n",
    "# resize_shape = model.output_shape[2] * model.output_shape[3]\n",
    "# model.add(Reshape((model.output_shape[1], resize_shape)))\n",
    "\n",
    "# model.add(Permute((2, 1), input_shape=(10, 64)))\n",
    "# now: model.output_shape == (None, 64, 10)\n",
    "\n",
    "# Conv1D , input_shape=(10, 128) for time series sequences of 10 time steps with 128 features per step\n",
    "# 1st conv\n",
    "layer = Conv1D(filters=CONV_FILTER_COUNT,\n",
    "               kernel_size=FILTER_LENGTH)(layer)  #(model_input)\n",
    "layer = Activation('relu')(layer)\n",
    "layer = MaxPooling1D(pool_size=POOL_SIZE, strides=POOL_SIZE)(layer)\n",
    "layer = Dropout(0.2)(layer)\n",
    "\n",
    "for i in range(N_LAYERS - 1):\n",
    "    layer = Conv1D(filters=128, kernel_size=FILTER_LENGTH)(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = MaxPooling1D(pool_size=POOL_SIZE, strides=POOL_SIZE)(layer)\n",
    "    layer = Dropout(0.4)(layer)\n",
    "\n",
    "## LSTM Layer\n",
    "layer = GRU(GRU_COUNT, return_sequences=True)(layer)\n",
    "layer = GRU(GRU_COUNT, return_sequences=False)(layer)\n",
    "\n",
    "layer = Dropout(0.4)(layer)\n",
    "\n",
    "## Softmax Output\n",
    "layer = Dense(NUM_CLASSES)(layer)\n",
    "layer = Activation('softmax')(layer)\n",
    "model_output = layer\n",
    "\n",
    "#model_output = Dense(NUM_CLASSES, activation='relu')(model_output)\n",
    "\n",
    "#Create your model\n",
    "train_model = Model(inputs=model_input, outputs=model_output)\n",
    "\n",
    "#compile\n",
    "train_model.compile(loss='categorical_crossentropy',\n",
    "                    optimizer=Adam(lr=0.001),\n",
    "                    metrics=['accuracy'],\n",
    "                    target_tensors=[label])\n",
    "\n",
    "#Train the model\n",
    "#steps per epoch could be viewed as dataset/batchsize\n",
    "# Better to change checkpoint name before run\n",
    "train_model.fit(epochs=70,\n",
    "                steps_per_epoch=num_train//BATCH_SIZE,\n",
    "                validation_data=(lmfcc_val, label_val),\n",
    "                validation_steps=num_val//BATCH_SIZE,\n",
    "                callbacks=get_callbacks(checkpoint_name=\"trail\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 256)          0         \n",
      "_________________________________________________________________\n",
      "permute_1 (Permute)          (None, 256, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 252, 64)           41024     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 252, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 126, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 126, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 122, 128)          41088     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 122, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 61, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 61, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 57, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 57, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 28, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 28, 128)           0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 28, 64)            37056     \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 64)                24768     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                780       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 12)                0         \n",
      "=================================================================\n",
      "Total params: 226,764\n",
      "Trainable params: 226,764\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "train_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inp (?, 128, 256)\n",
      "inp (?, 1, 12)\n",
      "inp (?, 128, 256)\n",
      "inp (?, 1, 12)\n",
      "(?, 128, 256)\n",
      "(?, 256, 128)\n",
      "Epoch 1/70\n",
      "672/672 [==============================] - 635s 945ms/step - loss: 2.3409 - acc: 0.1778 - val_loss: 2.2673 - val_acc: 0.1803\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.18030, saving model to ../models/trail01-2.27.hdf5\n",
      "Epoch 2/70\n",
      "672/672 [==============================] - 653s 972ms/step - loss: 2.2906 - acc: 0.1812 - val_loss: 2.2655 - val_acc: 0.1799\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.18030\n",
      "Epoch 3/70\n",
      "672/672 [==============================] - 676s 1s/step - loss: 2.2811 - acc: 0.1810 - val_loss: 2.2618 - val_acc: 0.1803\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.18030\n",
      "Epoch 4/70\n",
      "672/672 [==============================] - 645s 960ms/step - loss: 2.2763 - acc: 0.1810 - val_loss: 2.2610 - val_acc: 0.1802\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.18030\n",
      "Epoch 5/70\n",
      "382/672 [================>.............] - ETA: 3:52 - loss: 2.2763 - acc: 0.1819"
     ]
    }
   ],
   "source": [
    "#RNN\n",
    "\n",
    "#Build network\n",
    "NUM_CLASSES = 12  # Must Change in the tf reader as well\n",
    "N_LAYERS = 3\n",
    "CONV_FILTER_COUNT = 64\n",
    "FILTER_LENGTH = 5\n",
    "\n",
    "POOL_SIZE = 2\n",
    "\n",
    "GRU_COUNT = 64\n",
    "NUM_HIDDEN = 128\n",
    "L2_regularization = 0.001\n",
    "\n",
    "# Input\n",
    "model_input = keras.layers.Input(tensor=lmfcc)\n",
    "print(model_input.shape)\n",
    "layer = Permute((2, 1), input_shape=(128, 256))(model_input)\n",
    "print(layer.shape)\n",
    "# resize_shape = model.output_shape[2] * model.output_shape[3]\n",
    "# model.add(Reshape((model.output_shape[1], resize_shape)))\n",
    "\n",
    "# model.add(Permute((2, 1), input_shape=(10, 64)))\n",
    "# now: model.output_shape == (None, 64, 10)\n",
    "\n",
    "## LSTM Layer\n",
    "layer = LSTM(GRU_COUNT, return_sequences=True)(layer)\n",
    "layer = LSTM(GRU_COUNT, return_sequences=False)(layer)\n",
    "\n",
    "## Softmax Outputstart with 0.001 and my guess by the way steps per epoch is happening, i dont think it is seeing all samples in each epoch and thus would take more epochs to decrease the decrease the loss\n",
    "layer = Dense(NUM_CLASSES)(layer)\n",
    "layer = Activation('softmax')(layer)\n",
    "model_output = layer\n",
    "\n",
    "#model_output = Dense(NUM_CLASSES, activation='relu')(model_output)\n",
    "\n",
    "#Create your model\n",
    "train_model = Model(inputs=model_input, outputs=model_output)\n",
    "\n",
    "#compile\n",
    "train_model.compile(loss='categorical_crossentropy',\n",
    "                    optimizer=Adam(lr=0.01),\n",
    "                    metrics=['accuracy'],\n",
    "                    target_tensors=[label])\n",
    "\n",
    "#Train the model\n",
    "#steps per epoch could be viewed as dataset/batchsize\n",
    "batch_size = 32\n",
    "# Better to change checkpoint name before run\n",
    "train_model.fit(epochs=70,\n",
    "                steps_per_epoch=num_train//batch_size,\n",
    "                validation_data=(lmfcc_val, label_val),\n",
    "                validation_steps=num_val//batch_size,\n",
    "                callbacks=get_callbacks(checkpoint_name=\"trail\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
